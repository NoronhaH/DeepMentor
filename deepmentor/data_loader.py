# Execu√ß√£o
# python3 -m deepmentor.data_loader download-book
# python3 -m deepmentor.data_loader prepare-images
# python3 -m deepmentor.data_loader run-ocr
# python3 -m deepmentor.data_loader calculate-tokens

from PIL import Image
from IPython.display import display
import typer
import requests
import sys
import warnings
import json
import tiktoken
from pathlib import Path
from tqdm import tqdm
from PyPDF2 import PdfReader
from pdf2image import convert_from_path

# Ignora warnings para um output mais limpo
warnings.filterwarnings('ignore')


try:
    # ADICIONADO 'GPT_MODEL' para o tiktoken
    from .config import (
        D2L_BOOK_LINK, BOOKS_PATH, KNOWLEDGE_DIR, OCR_DPI, logger,
        NEURALMIND_API_KEY, NEURALMIND_OCR_URL, 
        NEURALMIND_API_USE, OCR_PAGES, GPT_MODEL 
    )
except ImportError:
    print("‚ùå Erro: N√£o foi poss√≠vel importar 'deepmentor.config'.")
    print("   Certifique-se de que voc√™ ativou o ambiente virtual (.venv) e")
    print("   instalou o projeto com 'pip install -U -r requirements.txt' (que inclui o '-e .')")
    sys.exit(1)

app = typer.Typer(
    help="Scripts para carregar e preparar dados para o DeepMentor.",
    add_completion=False
)


@app.command()
def download_book():
    """
    Baixa o livro 'Dive into Deep Learning' (d2l-en.pdf).
    """
    
    logger.info(f"Diret√≥rio de destino: {BOOKS_PATH}")
    BOOKS_PATH.mkdir(parents=True, exist_ok=True)
    
    pdf_path = BOOKS_PATH / "d2l-en.pdf"

    if pdf_path.exists():
        logger.info(f"O arquivo '{pdf_path.name}' j√° existe. Download pulado.")
        return

    logger.info(f"üì• Baixando o livro de {D2L_BOOK_LINK}...")
    try:
        response = requests.get(D2L_BOOK_LINK, stream=True)
        response.raise_for_status()  # Dispara erro se o download falhar
        with open(pdf_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        logger.info(f"‚úÖ Download conclu√≠do! Arquivo salvo em: {pdf_path}")
    except requests.exceptions.RequestException as e:
        logger.error(f"‚ùå Falha no download: {e}")
        raise typer.Exit(code=1)


@app.command()
def prepare_images():
    """
    Converte as p√°ginas do PDF 'd2l-en.pdf' em imagens PNG.
    """
    logger.info("Iniciando convers√£o de PDF para PNG...")
    
    # Caminhos
    pdf_path = BOOKS_PATH / "d2l-en.pdf"
    output_dir = BOOKS_PATH / "pages"
    ocrdata_file = KNOWLEDGE_DIR / "d2l-ocr.json"

    # Garante que os diret√≥rios existam
    output_dir.mkdir(parents=True, exist_ok=True)
    KNOWLEDGE_DIR.mkdir(parents=True, exist_ok=True)

    if not pdf_path.exists():
        logger.error(f"‚ùå PDF n√£o encontrado em {pdf_path}.")
        logger.error("Rode 'python3 -m deepmentor.data_loader download-book' primeiro.")
        raise typer.Exit(code=1)

    try:
        total_pages = len(PdfReader(pdf_path).pages)
    except Exception as e:
        logger.error(f"‚ùå Erro ao ler o PDF: {e}")
        raise typer.Exit(code=1)

    # Carregar resultados pr√©vios (se houver)
    if ocrdata_file.exists():
        with open(ocrdata_file, "r", encoding="utf-8") as f:
            summary_dict = json.load(f)
    else:
        summary_dict = {}

    if not summary_dict:
        logger.info(f"üìò Processando {total_pages} p√°ginas...")

    pages_converted = 0
    for i in tqdm(range(1, total_pages + 1), desc="Convertendo PDF"):
        page_key = str(i)
        if page_key in summary_dict:
            continue  # P√°gina j√° processada e registrada no JSON

        img_path = output_dir / f"page_{i:04d}.png"

        # Converter para PNG se ainda n√£o existir
        if not img_path.exists():
            try:
                images = convert_from_path(pdf_path, dpi=OCR_DPI, first_page=i, last_page=i)
                if not images:
                    logger.warning(f"‚ö†Ô∏è Falha ao converter p√°gina {i}")
                    continue
                images[0].save(img_path, "PNG")
                pages_converted += 1
            except Exception as e:
                logger.error(f"‚ùå Erro ao converter p√°gina {i}: {e}")
                continue

    logger.info(f"‚úÖ Convers√£o completa! {pages_converted} novas p√°ginas convertidas.")
    logger.info(f"Imagens salvas em: {output_dir}")

    # AVISO: A linha abaixo (display) pode falhar em terminais puros.
    # √â segura em notebooks (Jupyter, VS Code Notebooks).
    try:
        img = Image.open(output_dir / "page_0049.png")
        display(img)
    except Exception:
        logger.info("N√£o foi poss√≠vel exibir a imagem de amostra no terminal.")


@app.command()
def run_ocr():
    """
    Executa o OCR da NeuralMind nas imagens PNG geradas.
    """
    if not NEURALMIND_API_USE:
        logger.warning("‚ö†Ô∏è OCR pulado. 'NEURALMIND_API_USE' est√° 'False' no config.py.")
        return

    logger.info("Iniciando processo de OCR com a API NeuralMind...")
    logger.info(f"Iniciando comunica√ß√£o: {NEURALMIND_OCR_URL}")

    # Caminhos
    output_dir = BOOKS_PATH / "pages"
    ocrdata_file = KNOWLEDGE_DIR / "d2l-ocr.json"
    KNOWLEDGE_DIR.mkdir(parents=True, exist_ok=True)

    # Carregar resultados pr√©vios (se houver)
    if ocrdata_file.exists():
        with open(ocrdata_file, "r", encoding="utf-8") as f:
            ocr_content_dict = json.load(f)
    else:
        ocr_content_dict = {}

    # Configura√ß√£o da API
    url_neural_mind = NEURALMIND_OCR_URL
    headers = {
        "accept": "application/json",
        "X-API-KEY": NEURALMIND_API_KEY
    }

    pages_processed = 0
    try:
        for page in tqdm(OCR_PAGES, desc="Se√ß√µes OCR"):
            section = page["section"]
            start_page = page["start_page"]
            end = page["end"]

            # Garante que a se√ß√£o exista no dicion√°rio
            if section not in ocr_content_dict:
                ocr_content_dict[section] = {}

            for i in tqdm(range(start_page, end + 1), desc=f"OCR ({section})", leave=False):
                if str(i) in ocr_content_dict[section]:
                    continue

                page_key = f"page_{i:04d}.png"
                img_path = output_dir / page_key

                if not img_path.exists():
                    logger.warning(f"‚ö†Ô∏è Imagem {img_path} n√£o encontrada. Pule 'prepare-images'?")
                    continue

                files = {"image": (page_key, open(img_path, "rb"), "image/png")}
                data = {
                    "prompt": f"<image>\nFree OCR.",
                    "temperature": "0", "max_tokens": "8192", "ngram_size": "30",
                    "window_size": "90", "skip_special_tokens": "false"
                }

                try:
                    response = requests.post(
                        url_neural_mind, headers=headers, files=files, data=data, timeout=300
                    )
                    response.raise_for_status()
                    result = response.json()
                    ocr_content_dict.setdefault(section, {})[str(i)] = {"text": result['text']}
                    pages_processed += 1
                except requests.exceptions.RequestException as e:
                    logger.error(f"‚ùå Erro no OCR para p√°gina {i}: {e}")
    finally:
        # Salva os resultados
        if pages_processed > 0:
            with open(ocrdata_file, "w", encoding="utf-8") as f:
                json.dump(ocr_content_dict, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ OCR Conclu√≠do. {pages_processed} novas p√°ginas processadas.")
            logger.info(f"Resultados salvos em {ocrdata_file}")
        else:
            logger.info("‚úÖ OCR Conclu√≠do. Nenhuma p√°gina nova processada.")


try:
    _encoder = tiktoken.encoding_for_model(GPT_MODEL)
except Exception:
    logger.warning(f"Falha ao carregar encoding do GPT_MODEL '{GPT_MODEL}'. Usando 'cl100k_base'.")
    _encoder = tiktoken.get_encoding("cl100k_base")

def count_tokens(string: str) -> int:
    """Retorna o n√∫mero de tokens em uma string de texto."""
    if not string:
        return 0
    return len(_encoder.encode(string))

@app.command()
def calculate_tokens():
    """
    Calcula os tokens (usando tiktoken) para o 'd2l-ocr.json'.
    
    L√™ o arquivo JSON gerado pelo 'run-ocr', conta os tokens
    para cada p√°gina e exibe um relat√≥rio por se√ß√£o.
    """
    logger.info(f"Iniciando contagem de tokens (usando '{_encoder.name}')...")

    # Caminho do arquivo de dados
    ocrdata_file = KNOWLEDGE_DIR / "d2l-ocr.json"

    if not ocrdata_file.exists():
        logger.error(f"‚ùå Arquivo OCR n√£o encontrado em {ocrdata_file}")
        logger.error("   Execute 'python3 -m deepmentor.data_loader run-ocr' primeiro.")
        raise typer.Exit(code=1)

    # Carregar o arquivo JSON
    try:
        with open(ocrdata_file, "r", encoding="utf-8") as f:
            ocr_content_dict = json.load(f)
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå Erro ao ler o JSON: {e}")
        raise typer.Exit(code=1)
    
    if not ocr_content_dict:
        logger.warning("‚ö†Ô∏è O arquivo JSON est√° vazio. Nada para contar.")
        return

    logger.info("--- Relat√≥rio de Tokens ---")
    token_report = {}
    total_geral = 0

    for section, pages in ocr_content_dict.items():
        if not isinstance(pages, dict):
            logger.warning(f"Se√ß√£o '{section}' mal formatada. Pulando.")
            continue
            
        token_report[section] = {}
        section_total = 0
        
        logger.info(f"\nCalculando Se√ß√£o: '{section}'")
        for page, content in pages.items():
            text = content.get("text", "")
            num_tokens = count_tokens(text)
            token_report[section][page] = num_tokens
            section_total += num_tokens
            logger.info(f"  P√°gina: {page} ‚Üí {num_tokens} tokens")

        # Total por se√ß√£o
        logger.info(f"  Total da Se√ß√£o '{section}': {section_total} tokens")
        total_geral += section_total
    
    logger.info("\n--- Resumo Total ---")
    logger.info(f"  Total Geral (todas as se√ß√µes): {total_geral} tokens")
    logger.info("‚úÖ Contagem de tokens conclu√≠da.")

if __name__ == "__main__":
    app()