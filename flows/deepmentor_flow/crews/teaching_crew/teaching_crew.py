import os
from signal import pause
import sys
import time
import shutil
import json
import re
import asyncio
import threading
import yaml
import tiktoken
from pathlib import Path
from typing import Any, Dict, List, Tuple
from textwrap import dedent

# Adiciona a Raiz do Projeto ao Path
PROJ_ROOT = Path(__file__).resolve().parents[4] 
if str(PROJ_ROOT) not in sys.path:
    sys.path.append(str(PROJ_ROOT))

# Importa√ß√µes do Projeto e Bibliotecas
try:
    from deepmentor.config import (
        GPT_MODEL, OPENAI_API_KEY, logger,
        CREW_CONFIG_DIR, KNOWLEDGE_DIR, OLLAMA_API_BASE, LLM_MODEL, OLLAMA_MODEL,
        GRADIO_PUBLIC_SHARE
    )
    
    from crewai import Agent, Task, Crew, Process, LLM
    from crewai.flow.flow import Flow, listen, or_, and_, router, start
    #from crewai.project import CrewBase, agent, task, crew, llm, before_kickoff, after_kickoff
    from crewai.knowledge.source.json_knowledge_source import JSONKnowledgeSource
    from pydantic import BaseModel, Field, ValidationError, ConfigDict

    import gradio as gr

except ImportError as e:
    print(f"‚ùå Erro: N√£o foi poss√≠vel importar os m√≥dulos. {e}")
    print("   Certifique-se de que o .venv est√° ativo e as depend√™ncias est√£o instaladas.")
    print("   Tente: pip install pyyaml")
    sys.exit(1)

# --------------------------------
# Defini√ß√£o dos Estados (Pydantic)
# --------------------------------
class GeneratorExamplesOutput(BaseModel):
    examples: List[List[str]] = Field(description="Exemplos de conversa√ß√£o com base no tema/t√≥pico/hist√≥rico para o usu√°rio.")

class PresentationOutput(BaseModel):
    presentation_message: str = Field(description="Mensagem completa de apresenta√ß√£o para o aluno (em markdown).")
    user_name: str = Field(default="", description="Nome do usu√°rio informado, ou vazio se ainda n√£o foi informado.")
    available_topics: List[str] = Field(default_factory=list, description="Lista de t√≥picos dispon√≠veis na base de conhecimento.")
    user_interest_topics: List[str] = Field(default_factory=list, description="T√≥picos de interesse do usu√°rio.")
    user_focus_type: str = Field(default="", description="Tipo de foco desejado: 'te√≥rico', 'pr√°tico', 'equilibrado' ou vazio.")
    user_level: str = Field(default="", description="N√≠vel do usu√°rio: 'iniciante', 'intermedi√°rio', 'avan√ßado' ou vazio.")
    
    # Campos de satisfa√ß√£o para cada informa√ß√£o necess√°ria
    user_name_satisfied: str = Field(description="Status da coleta do nome: 'satisfied' ou 'not_satisfied'.")
    user_interest_satisfied: str = Field(description="Status da coleta de interesses: 'satisfied' ou 'not_satisfied'.")
    topic_selection_satisfied: str = Field(description="Status da sele√ß√£o de tema: 'satisfied' ou 'not_satisfied'.")
    user_focus_satisfied: str = Field(description="Status da coleta do tipo de foco: 'satisfied' ou 'not_satisfied'.")
    user_level_satisfied: str = Field(description="Status da coleta do n√≠vel: 'satisfied' ou 'not_satisfied'.")
    
    # Status geral
    all_requirements_met: bool = Field(default=False, description="True se todas as informa√ß√µes necess√°rias foram coletadas.")
    next_suggested_action: str = Field(description="Pr√≥xima a√ß√£o sugerida.")

class OrchestratorAnalysis(BaseModel):
    next_instruction: str = Field(description="A instru√ß√£o/a√ß√£o a executar: 'subject_choice', 'teaching_plan_ordering', 'end_session', etc.")

class ProfessorOutput(BaseModel):
    message_presentation: str = Field(description="Mensagem principal de apresenta√ß√£o para o usu√°rio (sempre preenchido).")
    edu_content: str = Field(default="", description="Conte√∫do de ensino gerado, se houver.")
    test_content: str = Field(default="", description="Descri√ß√£o/pergunta do teste gerada, se houver.")
    test_code: str = Field(default="", description="C√≥digo inicial/template para o teste, se houver.")
    result: str = Field(default="", description="Avalia√ß√£o, score ou feedback gerado, se houver.")
    mode: str = Field(description="Modo atual: 'teaching' (ensinando), 'testing' (aplicando teste), 'evaluating' (avaliando)")

class DeanOutput(BaseModel):
    teaching_plan: Dict[str, bool] = Field(description="O plano de ensino completo e atualizado. Cada t√≥pico √© mapeado para um booleano indicando se foi conclu√≠do (True) ou n√£o (False).")
    teaching_plan_progress: float = Field(description="O progresso atualizado do plano (0.0 a 1.0).")
    next_instruction_for_professor: str = Field(description="A pr√≥xima instru√ß√£o para o Professor, baseada nesta an√°lise.")

class TeachingPlanConfirmationOutput(BaseModel):
    confirmation_message: str = Field(description="Mensagem apresentando o plano de ensino e solicitando confirma√ß√£o do aluno.")
    plan_approved: bool = Field(description="Se o aluno aprovou o plano de ensino (true) ou solicitou revis√£o (false).")
    revision_feedback: str = Field(default="", description="Feedback do aluno sobre o que deve ser ajustado no plano, se houver.")

class InteractionState(BaseModel):
    model_config = ConfigDict(arbitrary_types_allowed=True)
    
    turn: int = 0
    agents: List[str] = []

    last_agent: str = ""
    last_instruction: str = ""
    next_agent: str = ""
    next_instruction: str = ""

    user_name: str = ""
    user_interest_topics: List[str] = []
    user_focus_type: str = ""  # Tipo de foco: "te√≥rico", "pr√°tico", "equilibrado"
    user_level: str = ""  # N√≠vel: "iniciante", "intermedi√°rio", "avan√ßado"
    available_topics: List[str] = []
    user_message: str = ""
    agent_response: str = ""
    edu_content: str = ""
    test_content: str = ""
    test_code: str = ""  # C√≥digo do teste atual
    user_code: str = ""  # C√≥digo submetido pelo usu√°rio
    conversation_history: List[str] = []
    
    teaching_plan: Dict[str, bool] = {}  # {t√≥pico: conclu√≠do (True/False)}
    teaching_plan_progress: float = 0.0
    
    user_feedback: str = ""
    result: str = ""

    # Base de Conhecimento (conte√∫do carregado)
    summary_d2l: str = ""
    chapter_3_d2l: str = ""  # Mudado de List[str] para str pois √© um objeto/string

    # Interface do Gradio (Vari√°vel Global)
    interface: gr.Interface = None
    chatbot: gr.Chatbot = None
    msg_input: gr.Textbox = None
    send_btn: gr.Button = None
    clear_btn: gr.Button = None
    code_output: gr.Code = None
    teaching_plan_checklist: gr.CheckboxGroup = None
    progress_bar: gr.Slider = None
    examples_dataset: gr.Dataset = None
    
    # Exemplos atuais (podem ser atualizados dinamicamente)
    current_examples: List[List[str]] = []

# --------------------------------
# Fun√ß√£o de Contagem de Tokens
# --------------------------------
def count_tokens(text: str, model: str = "gpt-4") -> int:
    """
    Conta o n√∫mero de tokens em um texto usando tiktoken.
    
    Args:
        text: Texto para contar tokens
        model: Modelo do GPT para usar o encoding correto
    
    Returns:
        N√∫mero de tokens
    """
    if not text:
        return 0
    
    try:
        encoder = tiktoken.encoding_for_model(model)
    except Exception:
        logger.warning(f"Falha ao carregar encoding do modelo '{model}'. Usando 'cl100k_base'.")
        encoder = tiktoken.get_encoding("cl100k_base")
    
    return len(encoder.encode(text))

# Defini√ß√£o do Flow
class DeepMentorFlow(Flow[InteractionState]):
    """Define o fluxo de orquestra√ß√£o do DeepMentor."""

    # Construtor da Classe DeepMentorFlow
    # - Carrega a base de conhecimento
    # - Carrega o LLM
    # - Carrega os arquivos de configura√ß√£o (.yaml)
    # - Define exemplos padr√£o (fallback)
    def __init__(self):
        super().__init__()

        # Carrega o conte√∫do do livro D2L para usar como contexto nas tasks
        d2l_json_path = KNOWLEDGE_DIR / "d2l-ocr.json"
        logger.info(f"üìö Carregando conte√∫do do D2L de: {d2l_json_path}")
        
        with open(d2l_json_path, 'r', encoding='utf-8') as f:
            self.d2l_data = json.load(f)  # Armazena o objeto completo para uso posterior
            self.state.summary_d2l = json.dumps(self.d2l_data.get('summary', {}), ensure_ascii=False, indent=2)
            self.state.chapter_3_d2l = json.dumps(self.d2l_data.get('chapter-3', {}), ensure_ascii=False, indent=2)
        
        # Contagem de tokens e caracteres
        summary_chars = len(self.state.summary_d2l)
        summary_tokens = count_tokens(self.state.summary_d2l, model=GPT_MODEL)
        chapter3_chars = len(self.state.chapter_3_d2l)
        chapter3_tokens = count_tokens(self.state.chapter_3_d2l, model=GPT_MODEL)
        
        logger.info(f"‚úÖ Summary carregado: {summary_chars:,} caracteres | {summary_tokens:,} tokens")
        logger.info(f"‚úÖ Chapter 3 carregado: {chapter3_chars:,} caracteres | {chapter3_tokens:,} tokens")
        logger.info(f"üìä Total: {summary_chars + chapter3_chars:,} caracteres | {summary_tokens + chapter3_tokens:,} tokens")

        # Carrega o LLM
        if LLM_MODEL == 0:
            self.llm = LLM(
                model=GPT_MODEL,
                base_url="https://api.openai.com/v1",
                api_key=OPENAI_API_KEY,
            )
        else:
            self.llm = LLM(
                model=OLLAMA_MODEL,
                base_url=OLLAMA_API_BASE,
                temperature=0.7
            )

        # Carrega os arquivos de configura√ß√£o (.yaml)
        config_path = str(CREW_CONFIG_DIR)
        agent_file = os.path.join(config_path, 'agents.yaml')
        task_file = os.path.join(config_path, 'tasks.yaml')

        try:
            with open(agent_file, 'r', encoding='utf-8') as f:
                self.agent_definitions = yaml.safe_load(f)
            with open(task_file, 'r', encoding='utf-8') as f:
                self.task_definitions = yaml.safe_load(f)
            logger.info("Arquivos agents.yaml e tasks.yaml carregados.")

        except Exception as e:
            logger.error(f"Erro ao carregar arquivos .yaml: {e}")
            sys.exit(1)

        # Define exemplos padr√£o (fallback)
        self.default_examples = [
            ["Ol√°, como voc√™ est√°?"],
            ["Gostaria de aprender sobre Deep Learning!"],
            ["Gostaria de aprender sobre redes neurais profundas!"],
            ["Gostaria de aprender sobre otimiza√ß√£o de redes neurais!"]
        ]
        
        # Inicializa o estado com os exemplos padr√£o
        self.state.current_examples = self.default_examples

    # Inicializa o estado inicial do fluxo
    def initialize(self):
        """Inicializa o estado inicial do fluxo."""
        # Instancia a Interface Gradio
        # - Cria a Interface Gradio
        # - Aguarda primeira intera√ß√£o do usu√°rio para iniciar o fluxo (gerenciada pelo chat_callback)
        self.instance_gradio_interface()

    # Instancia a Interface Gradio
    def instance_gradio_interface(self):

        # Instancia o Gradio Interface
        print("üåê Criando Gradio Interface...")
        with gr.Blocks(theme=gr.themes.Soft()) as self.state.interface:
            gr.Markdown(
                "<center><h1>"
                "üéì DeepMentor: "
                "Ensino Adaptativo de Deep Learning"
                "</h1></center>"
            )
            
            with gr.Row():
                with gr.Column(scale=2):                    
                    # Componentes do chat
                    self.state.chatbot = gr.Chatbot(
                        value=[],
                        height=500,
                        type="messages",
                        label="Conversa"
                    )
                    
                    with gr.Row():
                        with gr.Column(scale=9):
                            self.state.msg_input = gr.Textbox(
                                placeholder="Digite sua mensagem aqui...",
                                #label="Digite sua mensagem aqui...",
                                show_label=False,
                                submit_btn=False,
                                autofocus=True,
                                lines=2,
                                scale=4
                            )

                            # Dataset de exemplos (atualiz√°vel dinamicamente)
                            gr.Markdown("**üí° Sugest√µes:**")
                            self.state.examples_dataset = gr.Dataset(
                                components=[self.state.msg_input],
                                samples=self.state.current_examples,
                                label="Clique para usar",
                                type="index"
                            )
                            
                            # Bot√£o para atualizar exemplos (teste)
                            #update_examples_btn = gr.Button("üîÑ Gerar Novos Exemplos", size="sm")
                    
                        with gr.Column(scale=1):
                            self.state.send_btn = gr.Button("üì§ Enviar", variant="primary", scale=1)
                            #self.state.clear_btn = gr.Button("üóëÔ∏è Limpar")
                
                with gr.Column(scale=1):
                    self.state.code_output = gr.Code(
                        label="C√≥digo Gerado",
                        language="python",
                        interactive=True,
                        lines=10
                    )

                    # Checklist para mostrar o plano de ensino (bloco din√¢mico: atualizado a cada itera√ß√£o)
                    gr.Markdown("**üìö Plano de Ensino:**")
                    self.state.teaching_plan_checklist = gr.CheckboxGroup(
                        choices=[],
                        value=[],  # Itens marcados (ser√° atualizado conforme o progresso)
                        label="T√≥picos do Plano",
                        interactive=False  # Apenas para visualiza√ß√£o
                    )
                    
                    # Progress bar para visualizar o progresso geral
                    self.state.progress_bar = gr.Slider(
                        minimum=0,
                        maximum=100,
                        value=0,
                        label="Progresso (%)",
                        interactive=False
                    )
            
            # Eventos
            self.state.send_btn.click(
                self.chat_callback, 
                [self.state.msg_input, self.state.chatbot, self.state.code_output], 
                [
                    self.state.msg_input,
                    self.state.chatbot,
                    self.state.teaching_plan_checklist,
                    self.state.progress_bar,
                    self.state.examples_dataset,
                    self.state.code_output
                ]
            )

            self.state.msg_input.submit(
                self.chat_callback, 
                [self.state.msg_input, self.state.chatbot, self.state.code_output], 
                [
                    self.state.msg_input,
                    self.state.chatbot,
                    self.state.teaching_plan_checklist,
                    self.state.progress_bar,
                    self.state.examples_dataset,
                    self.state.code_output
                ]
            )

            #self.state.clear_btn.click(
            #    lambda: ([], ""),
            #    None,
            #    [self.state.chatbot, self.state.msg_input]
            #)
            
            # Evento para clicar em exemplo
            self.state.examples_dataset.select(
                self.select_example,
                None,  # N√£o precisa de inputs
                [self.state.msg_input]
            )
            
            # Evento para atualizar exemplos
            """update_examples_btn.click(
                self.update_examples,
                None,
                [examples_dataset]
            )"""
        
        print("‚úÖ Gradio Interface criada!")

        self.state.interface.launch(
            prevent_thread_lock=False,
            share=GRADIO_PUBLIC_SHARE
        )
        
        logger.info("üöÄ DeepMentor v1.0 iniciado.")


    # Callback do chat
    def chat_callback(self, message: str, history: list, user_code: str = ""):
        """Processa mensagens do chat e retorna todos os componentes atualizados."""
        logger.info(f"üí¨ Mensagem recebida: {message}")
        
        # Captura o c√≥digo do usu√°rio se houver
        if user_code and user_code.strip():
            self.state.user_code = user_code
            logger.info(f"üíª C√≥digo capturado do usu√°rio ({len(user_code)} caracteres)")
        
        # Atualiza o estado com a mensagem do usu√°rio ANTES de processar
        self.state.user_message = message
        self.state.conversation_history.append(f"User: {message}")
        
        # Se turn == 0, faz o kickoff do fluxo inicial
        if self.state.turn == 0:
            self.kickoff()  # Inicia o fluxo (executa start_flow e deepmentor_presentation)
            # Ap√≥s o kickoff, o estado j√° foi atualizado com a resposta

        if self.state.turn > 0 and self.state.next_instruction == "teaching_plan_ordering":
            # Inicia o flow orchestrator
            self.kickoff()
        # Se turn > 0 e ainda est√° na fase de apresenta√ß√£o, continua coletando informa√ß√µes
        elif self.state.next_instruction == "user message":
            logger.info("üîÑ Continuando coleta de informa√ß√µes do usu√°rio...")
            # Executa novamente a crew de apresenta√ß√£o para processar a nova mensagem
            self._execute_presentation_crew()
        # Se est√° aguardando confirma√ß√£o do plano de ensino
        elif self.state.next_instruction == "teaching_plan_confirmation":
            logger.info("üìã Processando confirma√ß√£o do plano de ensino...")
            # Executa a crew de confirma√ß√£o
            self._execute_teaching_plan_confirmation_crew()
            # Se foi aprovado ou precisa de revis√£o, continua o fluxo
            if self.state.next_instruction == "start_teaching":
                logger.info("‚úÖ Plano aprovado, iniciando ensino")
                # Continua o fluxo normal
                self.kickoff()
            elif self.state.next_instruction == "teaching_plan_revision":
                logger.info("üîÑ Revisando plano conforme feedback")
                # Volta para o Dean revisar
                self.kickoff()
        # Se est√° em modo de ensino cont√≠nuo (Professor aguardando resposta)
        elif self.state.next_instruction == "user_message" and self.state.last_instruction == "continue_teaching":
            logger.info("üìö Continuando ensino com Professor...")
            # Chama o professor diretamente para processar a mensagem do usu√°rio
            # Atualiza a instru√ß√£o para indicar que est√° no modo teaching
            self.state.next_instruction = "teaching"
            self.kickoff()  # Vai direto para o professor via router
        
        # Retorna a resposta do agente atual
        response = self.state.agent_response
        
        # Incrementa o turno
        self.state.turn += 1
        
        # Adiciona resposta ao hist√≥rico interno
        self.state.conversation_history.append(f"Assistant ({self.state.last_agent}): {response}")
        
        # Atualiza o hist√≥rico do chat
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": response})
        
        # Atualiza o checklist baseado no progresso
        # Extrai os t√≥picos do teaching_plan se existir, sen√£o usa lista padr√£o
        if self.state.teaching_plan and isinstance(self.state.teaching_plan, dict):
            topics_list = list(self.state.teaching_plan.keys())
            # Identifica os t√≥picos conclu√≠dos baseado nos valores booleanos
            completed_indices = [i for i, topic in enumerate(topics_list) if self.state.teaching_plan[topic]]
            
            # Log para debug
            logger.debug(f"üìã Checklist: {len(topics_list)} t√≥picos, {len(completed_indices)} conclu√≠dos")
            for i, (topic, completed) in enumerate(self.state.teaching_plan.items()):
                logger.debug(f"   {i+1}. [{('‚úÖ' if completed else '‚¨ú')}] {topic}")
        else:
            topics_list = []
            completed_indices = []
        
        # Formata os choices e values para o CheckboxGroup
        choices = [f"{i+1}. {topic}" for i, topic in enumerate(topics_list)]
        completed_items = [choices[i] for i in completed_indices]
        
        # Atualiza o teaching_plan_progress baseado nos t√≥picos conclu√≠dos
        if len(topics_list) > 0:
            self.state.teaching_plan_progress = len(completed_indices) / len(topics_list)
        else:
            self.state.teaching_plan_progress = 0.0
        
        # Calcula o progresso em porcentagem
        progress_value = self.state.teaching_plan_progress * 100
        
        logger.debug(f"üìä Progresso calculado: {progress_value:.1f}%")
        
        # Atualiza o code_output com o test_code se houver teste ativo
        code_output_value = self.state.test_code if self.state.test_code else ""
        
        # Retorna SEMPRE os 6 valores esperados pelo Gradio
        return (
            "",  # Limpa o input
            history,  # Hist√≥rico atualizado
            gr.CheckboxGroup(choices=choices, value=completed_items),  # Checklist atualizado
            progress_value,  # Progresso
            gr.Dataset(samples=self.state.current_examples),  # Exemplos atualizados
            code_output_value  # C√≥digo do teste
        )
    
    # Update de exemplos
    def generate_dynamic_examples(self, topic: str = None) -> List[List[str]]:
        """
        Gera exemplos din√¢micos de conversa√ß√£o baseados no contexto atual.
        Se falhar, retorna exemplos padr√£o.
        """
        try:
            # Instancia√ß√£o do Agente Generator Examples
            generator_examples_agent = Agent(
                role=self.agent_definitions['generator_examples']['role'],
                goal=self.agent_definitions['generator_examples']['goal'],
                backstory=self.agent_definitions['generator_examples']['backstory'],
                llm=LLM(
                    model="ollama/gpt-oss:120b",
                    base_url=OLLAMA_API_BASE,
                    temperature=0.7
                ),
                verbose=False
            )

            # Instancia√ß√£o da Tarefa do Generator Examples
            generator_examples_task = Task(
                description=self.task_definitions['generator_examples_task']['description'].format(
                    teaching_plan=self.state.teaching_plan or "Ainda n√£o definido",
                    teaching_plan_progress=self.state.teaching_plan_progress,
                    conversation_history="\n".join(self.state.conversation_history) or "Primeira intera√ß√£o",
                    user_message=self.state.user_message or "Nenhuma mensagem ainda"
                ),
                expected_output=self.task_definitions['generator_examples_task']['expected_output'],
                agent=generator_examples_agent,
                output_pydantic=GeneratorExamplesOutput
            )

            # Execu√ß√£o da Crew
            crew = Crew(
                agents=[generator_examples_agent],
                tasks=[generator_examples_task],
                process=Process.sequential,
                verbose=False
            )
            
            result = crew.kickoff()

            # Parser
            analysis = result.pydantic

            if not analysis or not analysis.examples:
                raise ValueError("O resultado Pydantic do Generator Examples foi None ou vazio.")

            new_examples = analysis.examples
            logger.info(f"‚úÖ Exemplos gerados com sucesso: {len(new_examples)} exemplos")

            return new_examples
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Falha ao gerar exemplos dinamicamente: {e}")
            logger.info("üìù Usando exemplos padr√£o")
            return self.default_examples
    
    # Atualiza os exemplos dinamicamente
    def update_examples(self):
        """Atualiza os exemplos dinamicamente (pode ser gerado por LLM)."""

        # Gera novos exemplos usando o m√©todo da classe
        new_examples = self.generate_dynamic_examples()
        self.state.current_examples = new_examples

        logger.info(f"üìù Exemplos atualizados: {len(new_examples)} novos exemplos")
        return ""
        #return gr.Dataset(samples=new_examples)

    # Callback do exemplo
    def select_example(self, evt: gr.SelectData):
        """Preenche o input quando um exemplo √© clicado."""
        # Usa os exemplos padr√£o se current_examples estiver vazio
        examples = self.state.current_examples if self.state.current_examples else self.default_examples
        
        # Retorna o texto do exemplo selecionado
        if evt.index < len(examples):
            return examples[evt.index][0]
        
        return ""


    ##############################################
    #################### Flow ####################
    ##############################################
    # Fluxo de Execu√ß√£o (Start)
    # Respons√°vel por inicializar o fluxo de execu√ß√£o do DeepMentor.
    # Inicializa a interface Gradio e o estado inicial do fluxo.
    # Envia a instru√ß√£o inicial para a Intera√ß√£o com o Usu√°rio.
    @start()
    def start_flow(self) -> Any:        
        # Inicializa vari√°veis se for a primeira vez
        if self.state.turn == 0:
            self.state.user_name = ""
            self.state.agent_response = ""
            self.state.last_agent = ""
            self.state.available_topics = []
            self.state.user_interest_topics = []
            self.state.teaching_plan_progress = 0.0
            self.state.current_examples = self.default_examples
            self.state.next_instruction = "deepmentor presentation"

            logger.info("Estado inicial definido.")
            logger.info("Acionando fluxo de apresenta√ß√£o do DeepMentor.")
            return ""
    
    # M√©todo auxiliar para executar a crew de apresenta√ß√£o
    def _execute_presentation_crew(self) -> bool:
        """
        Executa a crew de apresenta√ß√£o e atualiza o estado.
        Retorna True se todas as informa√ß√µes foram coletadas, False caso contr√°rio.
        """
        logger.info("üéì Executando crew de apresenta√ß√£o")
        
        # Atualiza o agente atual
        self.state.last_agent = self.agent_definitions['deepmentor_presentation']['role']

        # Instancia√ß√£o do Agente de Apresenta√ß√£o
        presentation_agent = Agent(
            role=self.agent_definitions['deepmentor_presentation']['role'],
            goal=self.agent_definitions['deepmentor_presentation']['goal'],
            backstory=self.agent_definitions['deepmentor_presentation']['backstory'],
            llm=self.llm,
            #knowledge_sources=[self.d2l_book_knowledge],  # Acesso √† base de conhecimento
            verbose=True
        )
        
        # Instancia√ß√£o da Tarefa de Apresenta√ß√£o
        presentation_task = Task(
            description=self.task_definitions['deepmentor_presentation_task']['description'].format(
                summary_d2l=self.state.summary_d2l,  # Adiciona o summary como par√¢metro
                turn=self.state.turn,
                user_name=self.state.user_name or "n√£o informado ainda",
                available_topics=self.state.available_topics if self.state.available_topics else "ainda n√£o consultado",
                user_message=self.state.user_message or "primeira intera√ß√£o",
                conversation_history="\n".join(self.state.conversation_history) if self.state.conversation_history else "primeira intera√ß√£o"
            ),
            expected_output=self.task_definitions['deepmentor_presentation_task']['expected_output'],
            agent=presentation_agent,
            output_pydantic=PresentationOutput
        )
        
        # Log do contexto atual (para debug)
        #logger.info(f"üìä Contexto da conversa:")
        #logger.info(f"   - Turno: {self.state.turn}")
        #logger.info(f"   - Nome: {self.state.user_name or 'n√£o informado'}")
        #logger.info(f"   - T√≥picos j√° listados: {len(self.state.available_topics) if self.state.available_topics else 0}")
        #logger.info(f"   - √öltima mensagem: {self.state.user_message[:50] if self.state.user_message else 'N/A'}...")
        #logger.info(f"   - Hist√≥rico: {len(self.state.conversation_history)} mensagens")
        
        # Execu√ß√£o da Crew
        crew = Crew(
            agents=[presentation_agent],
            tasks=[presentation_task],
            process=Process.sequential,
            verbose=True
        )
        
        result = crew.kickoff()
        
        # Parser e atualiza√ß√£o do estado
        try:
            presentation_output = result.pydantic
            
            if not presentation_output:
                raise ValueError("O resultado Pydantic da Apresenta√ß√£o foi None.")
            
            # Extrai a mensagem de apresenta√ß√£o do objeto pydantic
            self.state.agent_response = presentation_output.presentation_message

            # Atualiza o estado com as informa√ß√µes coletadas
            if presentation_output.user_name:
                self.state.user_name = presentation_output.user_name
                logger.info(f"üë§ Nome do usu√°rio identificado: {self.state.user_name}")
            
            if presentation_output.available_topics:
                self.state.available_topics = presentation_output.available_topics
                logger.info(f"üìö T√≥picos dispon√≠veis: {len(self.state.available_topics)} t√≥picos")
            
            if presentation_output.user_interest_topics:
                self.state.user_interest_topics = presentation_output.user_interest_topics
                logger.info(f"üí° Interesses: {', '.join(self.state.user_interest_topics)}")
            
            if presentation_output.user_focus_type:
                self.state.user_focus_type = presentation_output.user_focus_type
                logger.info(f"üéØ Tipo de foco: {self.state.user_focus_type}")
            
            if presentation_output.user_level:
                self.state.user_level = presentation_output.user_level
                logger.info(f"üìä N√≠vel do usu√°rio: {self.state.user_level}")
            
            # Log do status de satisfa√ß√£o
            logger.info(f"üìä Status de coleta:")
            logger.info(f"   - Nome: {presentation_output.user_name_satisfied}")
            logger.info(f"   - Interesses: {presentation_output.user_interest_satisfied}")
            logger.info(f"   - Tema selecionado: {presentation_output.topic_selection_satisfied}")
            logger.info(f"   - Tipo de foco: {presentation_output.user_focus_satisfied}")
            logger.info(f"   - N√≠vel: {presentation_output.user_level_satisfied}")
            logger.info(f"   - Todos requisitos: {'‚úÖ' if presentation_output.all_requirements_met else '‚ùå'}")
            
            # Incrementa o turno
            self.state.turn += 1
            
            # Decide pr√≥ximo passo baseado nos requisitos
            if presentation_output.all_requirements_met:
                logger.info("‚úÖ Todas as informa√ß√µes coletadas ‚Üí Pronto para pr√≥xima fase")
                
                # Salva informa√ß√µes importantes coletadas
                logger.info(f"üìù Informa√ß√µes salvas:")
                logger.info(f"   - Nome: {self.state.user_name}")
                logger.info(f"   - T√≥picos de interesse: {self.state.user_interest_topics}")
                logger.info(f"   - Tipo de foco: {self.state.user_focus_type}")
                logger.info(f"   - N√≠vel: {self.state.user_level}")
                logger.info(f"   - T√≥picos dispon√≠veis: {len(self.state.available_topics)} t√≥picos")
                
                # Reinicia o hist√≥rico de conversa√ß√£o (como solicitado)
                logger.info("üîÑ Reiniciando hist√≥rico de conversa√ß√£o para novo ciclo")
                self.state.conversation_history = []
                
                # Informa a √∫ltima instru√ß√£o na vari√°vel de estado
                self.state.last_instruction = "deepmentor presentation"
                
                # Informa a pr√≥xima instru√ß√£o na vari√°vel de estado
                # - encaminha ao orquestrador que a pr√≥xima instru√ß√£o √© de "teaching_plan_ordering"
                # - teaching_plan_ordering: respons√°vel por criar o plano de ensino inicial
                self.state.next_instruction = "teaching_plan_ordering"
                self.state.turn = 1  # Reseta o turno para 1 (novo ciclo), ciclo 0 √© somente para apresenta√ß√£o

                # Inicia o flow orchestrator
                # - O start_flow n√£o realiza nenhuma a√ß√£o ap√≥s o estado inicial e o Crew encaminha o fluxo para o router do orquestrador
                # - Com o valor diferente de "deepmentor presentation", o router do orquestrador encaminha para a rotina de teaching_plan_ordering com o Dean
                self.kickoff()

                return True
            else:
                logger.info("‚è∏Ô∏è  Aguardando mais informa√ß√µes do usu√°rio")
                self.state.last_instruction = "deepmentor presentation"
                self.state.next_instruction = "user message"
                return False
                
        except (ValidationError, TypeError, ValueError) as e:
            logger.error(f"‚ùå Erro ao processar apresenta√ß√£o: {e}")
            logger.error(f"   Resposta bruta: {result.raw}")
            self.state.agent_response = "Desculpe, ocorreu um erro. Pode repetir?"
            return False
    
    # Fluxo de Apresenta√ß√£o (Router):
    @router("deepmentor presentation")
    def deepmentor_presentation(self) -> str:
        """
        Apresenta√ß√£o do DeepMentor e boas-vindas ao usu√°rio.
        - Apresenta o DeepMentor e sua miss√£o
        - Pergunta o nome do usu√°rio
        - Informa os temas dispon√≠veis na base de conhecimento
        - Prepara o terreno para a cria√ß√£o do plano de ensino
        """
        logger.info("üéì Iniciando apresenta√ß√£o do DeepMentor")
        
        # Executa a crew de apresenta√ß√£o
        all_info_collected = self._execute_presentation_crew()
        
        # Se todas as informa√ß√µes foram coletadas, direciona para o orquestrador
        if all_info_collected:
            logger.info("‚úÖ Redirecionando para orquestrador")
            return "flow orchestrator"
        else:
            # Aguarda pr√≥xima mensagem do usu√°rio
            return ""
    
    # Orquestrador de Fluxo:
    @router(
        or_(
            start_flow,
            "flow orchestrator" # condi√ß√£o de retorno do orquestrador de fluxo (id de escuta)
        )
    )
    def flow_orchestrator(self) -> str:
        """
        Orquestrador √© respons√°vel por decidir qual o pipeline de execu√ß√£o a seguir.
        """
        # Por padr√£o: se a instru√ß√£o for de apresenta√ß√£o, encaminha automaticamente para o fluxo de apresenta√ß√£o
        if self.state.next_instruction == "deepmentor presentation":
            return "deepmentor presentation"
        
        # Se a instru√ß√£o for qualquer outra, continua o fluxo do orquestrador
        logger.info(f"üéØ Orchestrator - Instru√ß√£o: {self.state.next_instruction}")

        # Instancia√ß√£o do Agente Orchestrator
        orchestrator_agent = Agent(
            role=self.agent_definitions['orchestrator']['role'],
            goal=self.agent_definitions['orchestrator']['goal'],
            backstory=self.agent_definitions['orchestrator']['backstory'],
            llm=self.llm
        )

        # Instancia√ß√£o da Tarefa do Orchestrator
        orchestrator_task = Task(
            description=self.task_definitions['orchestrator_task']['description'].format(
                user_name=self.state.user_name or "n√£o informado",
                user_interest_topics=", ".join(self.state.user_interest_topics) if self.state.user_interest_topics else "n√£o informado",
                user_focus_type=self.state.user_focus_type or "n√£o informado",
                user_level=self.state.user_level or "n√£o informado",
                available_topics=", ".join(self.state.available_topics) if self.state.available_topics else "n√£o consultado",
                turn=self.state.turn,
                last_agent=self.state.last_agent,
                last_instruction=self.state.last_instruction,
                user_message=self.state.user_message or "nenhuma",
                teaching_plan_progress=self.state.teaching_plan_progress,
                teaching_plan=self.state.teaching_plan or "ainda n√£o criado",
                conversation_history="\n".join(self.state.conversation_history) if self.state.conversation_history else "hist√≥rico vazio"
            ),
            expected_output=self.task_definitions['orchestrator_task']['expected_output'],
            agent=orchestrator_agent,
            output_pydantic=OrchestratorAnalysis
        )

        # Instancia√ß√£o da Crew
        crew = Crew(
            agents=[orchestrator_agent],
            tasks=[orchestrator_task],
            process=Process.sequential,
            verbose=True
        )

        result = crew.kickoff()

        # Parser
        try:
            analysis = result.pydantic

            if not analysis:
                raise ValueError("O resultado Pydantic do Orquestrador foi None.")

            # Atualiza o estado com a an√°lise do orquestrador
            self.state.turn += 1
            self.state.next_instruction = analysis.next_instruction
            
            logger.info(f"‚úÖ Orquestrador:")
            logger.info(f"   - Pr√≥xima instru√ß√£o: {self.state.next_instruction}")

            # Roteamento baseado na instru√ß√£o do orquestrador
            if self.state.next_instruction == "teaching_plan_ordering":
                logger.info("‚û°Ô∏è  Direcionando para: Teaching Plan Dean Debate")
                return "teaching plan: dean debate"
            
            # Instru√ß√µes do Professor (podem vir como "call_professor:*")
            elif self.state.next_instruction.startswith("call_professor:"):
                action = self.state.next_instruction.split(":", 1)[1] if ":" in self.state.next_instruction else ""
                logger.info(f"‚û°Ô∏è  Direcionando para Professor: {action}")
                # Atualiza a instru√ß√£o para o professor processar
                self.state.next_instruction = action
                return "teaching"
            
            # Outras instru√ß√µes espec√≠ficas
            elif self.state.next_instruction == "subject_choice":
                logger.info("‚û°Ô∏è  Direcionando para: Subject Choice Dean Consult")
                return "subject choice: dean consult"
            
            elif self.state.next_instruction == "start_teaching":
                logger.info("‚û°Ô∏è  Direcionando para: Teaching Plan Professor Debate")
                return "teaching plan: professor debate"
            
            elif self.state.next_instruction == "end_session":
                logger.info("‚úÖ Sess√£o finalizada pelo orquestrador")
                self.state.agent_response = f"Obrigado {self.state.user_name}! Foi um prazer ensinar voc√™. At√© a pr√≥xima! üëã"
                return ""
            
            else:
                logger.warning(f"‚ö†Ô∏è  Instru√ß√£o n√£o reconhecida: {self.state.next_instruction}")
                logger.info("üìù Finalizando fluxo")
                return ""
            
        except (ValidationError, TypeError, ValueError) as e:
            logger.error(f"‚ùå O Orquestrador retornou dados inv√°lidos: {e}")
            logger.error(f"   Resposta bruta: {result.raw}")
            return ""
    
        
    # --------------------------------------------------
    # Fluxo 1: Cria√ß√£o e Atualiza√ß√£o do Plano de Ensino
    # --------------------------------------------------
    @router("teaching plan: dean debate")
    def teaching_plan_dean_debate(self) -> str:
        # Verifica se √© cria√ß√£o ou revis√£o
        is_revision = self.state.user_feedback != ""
        
        if is_revision:
            logger.info("üîÑ Dean: Revisando plano de ensino com feedback do aluno")
            print("dean: teaching plan revision task")
        else:
            logger.info("üéì Dean: Criando plano de ensino personalizado")
            print("dean: teaching plan task")
        
        try:
            # Extrai o cap√≠tulo escolhido pelo usu√°rio
            selected_topic = self.state.user_interest_topics[0] if self.state.user_interest_topics else ""
            
            # Identifica qual cap√≠tulo carregar (ex: "Cap√≠tulo 3: ..." ‚Üí "chapter-3")
            chapter_key = None
            for key in self.d2l_data.keys():
                if key != "summary" and selected_topic.lower() in str(self.d2l_data[key]).lower():
                    chapter_key = key
                    break
            
            # Se n√£o encontrou pelo conte√∫do, tenta pelo nome
            if not chapter_key:
                import re
                match = re.search(r'cap√≠tulo\s+(\d+)|chapter\s+(\d+)', selected_topic.lower())
                if match:
                    chapter_num = match.group(1) or match.group(2)
                    chapter_key = f"chapter-{chapter_num}"
            
            # Carrega o conte√∫do do cap√≠tulo
            chapter_content = ""
            if chapter_key and chapter_key in self.d2l_data:
                chapter_content = json.dumps(self.d2l_data[chapter_key], ensure_ascii=False, indent=2)
                logger.info(f"üìñ Cap√≠tulo carregado: {chapter_key}")
                logger.info(f"   Tamanho: {len(chapter_content)} caracteres")
            else:
                logger.warning(f"‚ö†Ô∏è Cap√≠tulo n√£o encontrado para: {selected_topic}")
                chapter_content = f"Conte√∫do sobre {selected_topic} (cap√≠tulo n√£o dispon√≠vel no momento)"
            
            # Instancia o agente Dean
            dean_agent = Agent(
                role=self.agent_definitions['dean_agent']['role'],
                goal=self.agent_definitions['dean_agent']['goal'],
                backstory=self.agent_definitions['dean_agent']['backstory'],
                llm=self.llm,
                verbose=True
            )
            
            # Instancia a task do Dean
            dean_task = Task(
                description=self.task_definitions['dean_task_teaching_plan_ordering']['description'].format(
                    user_name=self.state.user_name or "Aluno",
                    user_interest_topics=", ".join(self.state.user_interest_topics) if self.state.user_interest_topics else "n√£o especificado",
                    user_focus_type=self.state.user_focus_type or "equilibrado",
                    user_level=self.state.user_level or "iniciante",
                    chapter_content=chapter_content, # Conte√∫do completo do cap√≠tulo
                    user_feedback=self.state.user_feedback or "Nenhum feedback (primeira vez criando o plano)"
                ),
                expected_output=self.task_definitions['dean_task_teaching_plan_ordering']['expected_output'],
                agent=dean_agent,
                output_pydantic=DeanOutput
            )
            
            # Cria e executa a crew
            crew = Crew(
                agents=[dean_agent],
                tasks=[dean_task],
                process=Process.sequential,
                verbose=True
            )
            
            if is_revision:
                logger.info("üöÄ Revisando plano de ensino...")
            else:
                logger.info("üöÄ Criando plano de ensino...")
                
            result = crew.kickoff()
            
            # Parser do resultado
            dean_output = result.pydantic
            
            if not dean_output:
                raise ValueError("O resultado Pydantic do Dean foi None.")
            
            # Atualiza o estado com o plano de ensino
            self.state.teaching_plan = dean_output.teaching_plan
            self.state.teaching_plan_progress = dean_output.teaching_plan_progress
            
            # Log do plano criado/revisado
            action = "revisado" if is_revision else "criado"
            logger.info(f"‚úÖ Plano de ensino {action} com {len(self.state.teaching_plan)} t√≥picos:")
            for i, topic_name in enumerate(self.state.teaching_plan.keys(), 1):
                logger.info(f"   {i}. {topic_name}")
            
            # Cria mensagem para o usu√°rio com formata√ß√£o correta
            topic_list_md = "\n".join([f"{i}. {topic}" for i, topic in enumerate(self.state.teaching_plan.keys(), 1)])
            
            if is_revision:
                dean_message = dedent(f"""
                    üìö **Plano de Ensino Revisado!**
                    
                    {self.state.user_name}, ajustei o plano conforme seu feedback:
                    
                    **T√≥picos do Plano de Ensino:**
                    
                    {topic_list_md}
                    
                    **Configura√ß√£o:**
                    ‚Ä¢ Foco: {self.state.user_focus_type}
                    ‚Ä¢ N√≠vel: {self.state.user_level}
                    
                    **O que voc√™ acha agora?** O plano est√° melhor?
                    
                    Voc√™ pode:
                    ‚úÖ Aceitar o plano e come√ßar a aprender
                    üîÑ Solicitar mais ajustes (me diga o que gostaria de mudar)
                """).strip()
            else:
                dean_message = dedent(f"""
                    üìö **Plano de Ensino Criado!**
                    
                    Ol√° {self.state.user_name}! Analisei o {selected_topic} e criei um plano personalizado para voc√™:
                    
                    **T√≥picos do Plano de Ensino:**
                    
                    {topic_list_md}
                    
                    **Configura√ß√£o:**
                    ‚Ä¢ Foco: {self.state.user_focus_type}
                    ‚Ä¢ N√≠vel: {self.state.user_level}
                    
                    **O que voc√™ acha?** Este plano atende √†s suas expectativas?
                    
                    Voc√™ pode:
                    ‚úÖ Aceitar o plano e come√ßar a aprender
                    üîÑ Solicitar ajustes (me diga o que gostaria de mudar)
                """).strip()
            
            self.state.agent_response = dean_message
            self.state.last_agent = "Dean"
            self.state.next_instruction = "teaching_plan_confirmation"
            
            # Limpa o feedback ap√≥s usar
            if is_revision:
                self.state.user_feedback = ""
            
            logger.info(f"üì§ Mensagem do Dean preparada")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar plano de ensino: {e}")
            import traceback
            traceback.print_exc()
            
            # Mensagem de erro para o usu√°rio
            self.state.agent_response = f"Desculpe, {self.state.user_name}. Ocorreu um erro ao criar o plano de ensino. Por favor, tente novamente."
            self.state.last_agent = "Dean"
        
        return "teaching plan: confirmation"

    # M√©todo auxiliar para executar a crew de confirma√ß√£o do plano
    def _execute_teaching_plan_confirmation_crew(self) -> bool:
        """
        Executa a crew de confirma√ß√£o do plano de ensino.
        Retorna True se o plano foi aprovado, False se precisa de revis√£o.
        """
        logger.info("üìã Executando confirma√ß√£o do plano de ensino")
        
        # Instancia√ß√£o do Agente Dean para confirma√ß√£o
        dean_confirmation_agent = Agent(
            role=self.agent_definitions['dean_agent']['role'],
            goal=self.agent_definitions['dean_agent']['goal'],
            backstory=self.agent_definitions['dean_agent']['backstory'],
            llm=self.llm,
            verbose=True
        )
        
        # Instancia√ß√£o da Tarefa de Confirma√ß√£o
        dean_confirmation_task = Task(
            description=self.task_definitions['dean_task_teaching_plan_confirmation']['description'].format(
                user_name=self.state.user_name,
                teaching_plan=json.dumps({k: v for k, v in self.state.teaching_plan.items()}, ensure_ascii=False, indent=2),
                user_message=self.state.user_message,
                conversation_history="\n".join(self.state.conversation_history) if self.state.conversation_history else "primeira confirma√ß√£o"
            ),
            expected_output=self.task_definitions['dean_task_teaching_plan_confirmation']['expected_output'],
            agent=dean_confirmation_agent,
            output_pydantic=TeachingPlanConfirmationOutput
        )
        
        # Execu√ß√£o da Crew
        crew = Crew(
            agents=[dean_confirmation_agent],
            tasks=[dean_confirmation_task],
            process=Process.sequential,
            verbose=True
        )
        
        result = crew.kickoff()
        
        # Parser e atualiza√ß√£o do estado
        try:
            confirmation_output = result.pydantic
            
            if not confirmation_output:
                raise ValueError("O resultado Pydantic da Confirma√ß√£o foi None.")
            
            # Atualiza a resposta do agente
            self.state.agent_response = confirmation_output.confirmation_message
            
            # Incrementa o turno
            self.state.turn += 1
            
            if confirmation_output.plan_approved:
                logger.info("‚úÖ Plano de ensino aprovado pelo aluno!")
                self.state.last_instruction = "teaching_plan_confirmation"
                self.state.next_instruction = "start_teaching"
                return True
            else:
                logger.info(f"üîÑ Aluno solicitou revis√£o: {confirmation_output.revision_feedback}")
                self.state.last_instruction = "teaching_plan_confirmation"
                self.state.next_instruction = "teaching_plan_revision"
                # Armazena o feedback para revis√£o
                self.state.user_feedback = confirmation_output.revision_feedback
                return False
                
        except (ValidationError, TypeError, ValueError) as e:
            logger.error(f"‚ùå Erro ao processar confirma√ß√£o: {e}")
            logger.error(f"   Resposta bruta: {result.raw}")
            self.state.agent_response = "Desculpe, ocorreu um erro. Pode repetir se aprova o plano?"
            return False

    @router("teaching plan: confirmation")
    def teaching_plan_confirmation(self) -> str:
        """
        Aguarda a confirma√ß√£o do usu√°rio sobre o plano de ensino.
        Se aprovado, segue para o ensino. Se n√£o, volta para revis√£o.
        """
        logger.info("üìã Aguardando confirma√ß√£o do plano de ensino")
        
        # Executa a crew de confirma√ß√£o
        plan_approved = self._execute_teaching_plan_confirmation_crew()
        
        if plan_approved:
            logger.info("‚úÖ Redirecionando para in√≠cio do ensino")
            return "teaching plan: professor debate"
        else:
            # Volta para o Dean revisar o plano
            logger.info("üîÑ Redirecionando para revis√£o do plano")
            return "teaching plan: dean debate"

    
    # ---------------------------------------------
    # 3¬∫ Fluxo: Introdu√ß√£o e Explora√ß√£o de Conceito
    # ---------------------------------------------

    @router(
        or_(
            "teaching plan: professor debate",  # Vem da confirma√ß√£o do plano
            "teaching"  # Vem do callback quando usu√°rio responde durante ensino
        )
    )
    def teaching_plan_professor_debate(self) -> str:
        logger.info("üë®‚Äçüè´ Professor: Iniciando ensino do pr√≥ximo t√≥pico")
        print("professor: teaching task")
        
        try:
            # Identifica o pr√≥ximo t√≥pico a ser ensinado (primeiro com valor False)
            current_topic = None
            topic_index = 0
            for i, (topic_name, completed) in enumerate(self.state.teaching_plan.items()):
                if not completed:
                    current_topic = topic_name
                    topic_index = i
                    break
            
            if not current_topic:
                logger.warning("‚ö†Ô∏è Todos os t√≥picos j√° foram conclu√≠dos!")
                self.state.agent_response = "Parab√©ns! Voc√™ concluiu todos os t√≥picos do plano de ensino! üéâ"
                self.state.last_agent = "Professor"
                return "teaching plan: gui node"
            
            logger.info(f"üìñ T√≥pico atual: {current_topic}")
            
            # Extrai o cap√≠tulo escolhido pelo usu√°rio
            selected_topic = self.state.user_interest_topics[0] if self.state.user_interest_topics else ""
            
            # Identifica qual cap√≠tulo carregar
            chapter_key = None
            for key in self.d2l_data.keys():
                if key != "summary" and selected_topic.lower() in str(self.d2l_data[key]).lower():
                    chapter_key = key
                    break
            
            if not chapter_key:
                import re
                match = re.search(r'cap√≠tulo\s+(\d+)|chapter\s+(\d+)', selected_topic.lower())
                if match:
                    chapter_num = match.group(1) or match.group(2)
                    chapter_key = f"chapter-{chapter_num}"
            
            # Cria JSONKnowledge do cap√≠tulo apontando para o arquivo
            chapter_knowledge = None
            if chapter_key and chapter_key in self.d2l_data:
                # Monta o caminho para o arquivo JSON do cap√≠tulo espec√≠fico
                # chapter_key √© algo como "chapter-3", ent√£o o arquivo √© "chapter-3.json"
                chapter_json_path = f"{chapter_key}.json"
                
                try:
                    chapter_knowledge = JSONKnowledgeSource(
                        file_path=chapter_json_path,
                        metadata={"chapter": chapter_key, "selected_chapter": chapter_key}
                    )
                    logger.info(f"üìö Knowledge carregado do arquivo: {chapter_json_path}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar knowledge do arquivo: {e}")
                    # Se falhar, continua sem knowledge
                    chapter_knowledge = None
            
            # Instancia o agente Professor com knowledge
            professor_agent = Agent(
                role=self.agent_definitions['professor']['role'],
                goal=self.agent_definitions['professor']['goal'],
                backstory=self.agent_definitions['professor']['backstory'],
                llm=self.llm,
                knowledge_sources=[chapter_knowledge] if chapter_knowledge else [],
                verbose=True
            )
            
            # Calcula o contexto de progresso
            total_topics = len(self.state.teaching_plan)
            completed_topics = sum(1 for v in self.state.teaching_plan.values() if v)
            
            # Instancia a task do Professor
            professor_task = Task(
                description=self.task_definitions['professor_task_teach_topic']['description'].format(
                    user_name=self.state.user_name,
                    current_topic=current_topic,
                    topic_index=topic_index + 1,
                    total_topics=total_topics,
                    user_level=self.state.user_level,
                    user_focus_type=self.state.user_focus_type,
                    teaching_plan=json.dumps({k: v for k, v in self.state.teaching_plan.items()}, ensure_ascii=False, indent=2),
                    conversation_history="\n".join(self.state.conversation_history[-10:]) if self.state.conversation_history else "in√≠cio do ensino",
                    test_code=self.state.test_code or "Nenhum teste ativo no momento",
                    user_code=self.state.user_code or "Aluno ainda n√£o submeteu c√≥digo"
                ),
                expected_output=self.task_definitions['professor_task_teach_topic']['expected_output'],
                agent=professor_agent,
                output_pydantic=ProfessorOutput
            )
            
            # Cria e executa a crew
            crew = Crew(
                agents=[professor_agent],
                tasks=[professor_task],
                process=Process.sequential,
                verbose=True
            )
            
            logger.info(f"üöÄ Iniciando ensino do t√≥pico: {current_topic}")
            result = crew.kickoff()
            
            # Parser do resultado
            professor_output = result.pydantic
            
            if not professor_output:
                raise ValueError("O resultado Pydantic do Professor foi None.")
            
            # Processa baseado no modo do professor
            mode = professor_output.mode
            logger.info(f"üéØ Modo do Professor: {mode}")
            
            # A mensagem principal sempre vem do message_presentation
            base_message = dedent(f"""
                üìñ **T√≥pico {topic_index + 1}/{total_topics}: {current_topic}**
                
                {professor_output.message_presentation}
            """).strip()
            
            if mode == "teaching":
                # Professor est√° ensinando
                logger.info(f"üìñ Professor est√° ensinando o t√≥pico")
                
                if professor_output.edu_content:
                    professor_message = dedent(f"""
                        {base_message}
                        
                        ---
                        
                        {professor_output.edu_content}
                        
                        ---
                        
                        **Progresso:** {completed_topics}/{total_topics} t√≥picos conclu√≠dos ({int(self.state.teaching_plan_progress * 100)}%)
                    """).strip()
                else:
                    professor_message = base_message
                
                self.state.edu_content = professor_output.edu_content
                
            elif mode == "testing":
                # Professor est√° aplicando teste
                logger.info(f"üìù Professor est√° aplicando teste sobre o t√≥pico")
                
                professor_message = dedent(f"""
                    {base_message}
                    
                    ---
                    
                    **üìù Desafio:**
                    
                    {professor_output.test_content}
                    
                    ---
                    
                    **üíª Use o editor de c√≥digo ao lado para implementar sua solu√ß√£o.**
                    Quando terminar, clique em "Enviar" para submeter seu c√≥digo.
                """).strip()
                
                self.state.test_content = professor_output.test_content
                self.state.test_code = professor_output.test_code
                
                # Limpa o c√≥digo do usu√°rio (novo teste)
                self.state.user_code = ""
                
            elif mode == "evaluating":
                # Professor est√° avaliando
                logger.info(f"‚úÖ Professor est√° avaliando a resposta do aluno")
                
                professor_message = dedent(f"""
                    {base_message}
                    
                    ---
                    
                    {professor_output.result}
                    
                    ---
                    
                    **Progresso:** {completed_topics}/{total_topics} t√≥picos conclu√≠dos ({int(self.state.teaching_plan_progress * 100)}%)
                """).strip()
                
                self.state.result = professor_output.result
                
                # Se a avalia√ß√£o foi positiva, marca o t√≥pico como conclu√≠do
                if "aprovado" in professor_output.result.lower() or "correto" in professor_output.result.lower():
                    self.state.teaching_plan[current_topic] = True
                    completed_topics += 1
                    self.state.teaching_plan_progress = completed_topics / total_topics
                    logger.info(f"‚úÖ T√≥pico '{current_topic}' conclu√≠do!")
                    logger.info(f"üìä Progresso: {int(self.state.teaching_plan_progress * 100)}%")
                    
                    # Limpa os c√≥digos ap√≥s aprova√ß√£o
                    self.state.test_code = ""
                    self.state.user_code = ""
            else:
                logger.warning(f"‚ö†Ô∏è Modo desconhecido: {mode}")
                professor_message = base_message
            
            self.state.agent_response = professor_message
            self.state.last_agent = "Professor"
            self.state.last_instruction = "continue_teaching"
            self.state.next_instruction = "user_message"  # ‚úÖ Aguarda mensagem do usu√°rio
            
            logger.info(f"üì§ Conte√∫do do professor preparado (modo: {mode})")
            logger.info(f"‚è∏Ô∏è  Aguardando pr√≥xima mensagem do usu√°rio...")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao ensinar t√≥pico: {e}")
            import traceback
            traceback.print_exc()
            
            # Mensagem de erro para o usu√°rio
            self.state.agent_response = f"Desculpe, {self.state.user_name}. Ocorreu um erro ao ensinar o t√≥pico. Por favor, tente novamente."
            self.state.last_agent = "Professor"
            self.state.next_instruction = "user_message"
        
        # ‚úÖ Retorna vazio para sair do flow e voltar ao chat
        return ""

    # -----------------------------------------------------
    # TODO: 2¬∫ Fluxo: Verifica√ß√£o do cumprimento do Teaching Plan
    # -----------------------------------------------------